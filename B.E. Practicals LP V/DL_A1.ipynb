# %% [markdown]
# Linear Regression by Using Deep Neural Network

This Google Colab notebook demonstrates how to solve the Boston housing price prediction problem using a simple deep neural network (DNN) as a linear regressor. We will:

1. Load the dataset from a public URL
2. Explore and preprocess the data
3. Build a neural network model with TensorFlow Keras
4. Train and evaluate the model
5. Visualize training history and predictions

This notebook is written for Python 3.11.12 and is directly runnable in Google Colab.

---

# %% [markdown]
## 1. Setup and Imports

First, install any missing packages and import libraries.

```python
# If running in Colab, uncomment to install missing libs:
# !pip install -q tensorflow pandas matplotlib scikit-learn
```

# %%
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import tensorflow as tf
from tensorflow.keras import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.optimizers import Adam

print("TensorFlow version:", tf.__version__)

# %% [markdown]
## 2. Load the Dataset

We'll load the Boston housing dataset from a CSV hosted on GitHub.

# %%
df = pd.read_csv(
    'https://raw.githubusercontent.com/selva86/datasets/master/BostonHousing.csv'
)
df.head()

# %% [markdown]
## 3. Exploratory Data Analysis (EDA)

Check basic statistics and correlations.

# %%
print(df.shape)
df.describe()

# %%
# Correlation matrix heatmap
import seaborn as sns
plt.figure(figsize=(12, 10))
sns.heatmap(df.corr(), annot=True, fmt=".2f", cmap='coolwarm')
plt.title('Feature Correlation Matrix')
plt.show()

# %% [markdown]
## 4. Preprocessing

- Separate features and target
- Split into train/test sets
- Scale the features

# %%
# Separate inputs and output
y = df['medv'].values  # median house value
X = df.drop('medv', axis=1).values

# Split
a, b, c, d = train_test_split(X, y, test_size=0.2, random_state=42)
x_train, x_test, y_train, y_test = a, b, c, d

# Scale features
scaler = StandardScaler()
x_train = scaler.fit_transform(x_train)
x_test = scaler.transform(x_test)

print("Train shape:", x_train.shape)
print("Test shape:", x_test.shape)

# %% [markdown]
## 5. Build the Neural Network Model

We'll build a simple Sequential model with two hidden layers.

# %%
model = Sequential([
    Dense(64, activation='relu', input_shape=(x_train.shape[1],)),
    Dense(32, activation='relu'),
    Dense(1)  # output layer for regression
])

model.compile(
    optimizer=Adam(learning_rate=0.001),
    loss='mse',
    metrics=['mae']
)
model.summary()

# %% [markdown]
## 6. Train the Model

Train for 100 epochs, with 20% of training data used for validation.

# %%
history = model.fit(
    x_train, y_train,
    validation_split=0.2,
    epochs=100,
    batch_size=32,
    verbose=1
)

# %% [markdown]
## 7. Evaluate the Model

Evaluate on the test set and print results.

# %%
test_loss, test_mae = model.evaluate(x_test, y_test, verbose=0)
print(f"Test MSE: {test_loss:.2f}")
print(f"Test MAE: {test_mae:.2f}")

# %% [markdown]
## 8. Visualize Training History

Plot loss and MAE over epochs.

# %%
plt.figure(figsize=(12, 5))

# Loss plot
plt.subplot(1, 2, 1)
plt.plot(history.history['loss'], label='train loss')
plt.plot(history.history['val_loss'], label='val loss')
plt.xlabel('Epoch')
plt.ylabel('MSE')
plt.legend()
plt.title('Loss over Epochs')

# MAE plot
plt.subplot(1, 2, 2)
plt.plot(history.history['mae'], label='train MAE')
plt.plot(history.history['val_mae'], label='val MAE')
plt.xlabel('Epoch')
plt.ylabel('MAE')
plt.legend()
plt.title('MAE over Epochs')

plt.tight_layout()
plt.show()

# %% [markdown]
## 9. Predictions vs. True Values

Scatter plot of predicted vs actual prices.

# %%
y_pred = model.predict(x_test).flatten()
plt.figure(figsize=(6, 6))
plt.scatter(y_test, y_pred, alpha=0.7)
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')
plt.xlabel('True Prices')
plt.ylabel('Predicted Prices')
plt.title('True vs. Predicted House Prices')
plt.show()

# %% [markdown]
## 10. Sample Predictions

Print a few sample predictions alongside true values.

# %%
for i in range(5):
    print(f"True: {y_test[i]:.2f}, Predicted: {y_pred[i]:.2f}")

# %% [markdown]

---

This completes a simple DNN-based linear regression on the Boston housing dataset. Feel free to adjust architecture, hyperparameters, or try other regression models for comparison!
